from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import json

# Step 0: åŠ è½½çŸ¥è¯†ç‚¹æ•°æ®
with open("Catalog.json", "r", encoding="utf-8") as f:
    chapters = json.load(f)

# Step 1: åŠ è½½æ¨¡å‹
model = SentenceTransformer("moka-ai/m3e-base")

# Step 2: ç¼–ç ç« èŠ‚å
def get_chapter_vector(name: str) -> np.ndarray:
    vec = model.encode(name, normalize_embeddings=True)
    return vec

# Step 3: æ„å»ºç« èŠ‚å‘é‡åˆ—è¡¨
chapter_vectors = []
chapter_ids = []
chapter_names = []

for ch in chapters:
    vec = get_chapter_vector(ch["name"])
    chapter_vectors.append(vec)
    chapter_ids.append(ch["id"])
    chapter_names.append(ch["name"])

chapter_vectors = np.array(chapter_vectors)

# Step 4: æ„å»º FAISS ç´¢å¼•
dim = chapter_vectors.shape[1]
index = faiss.IndexFlatIP(dim)
index.add(chapter_vectors)

# Step 5: åŒ¹é…å‡½æ•°ï¼šè¾“å…¥é¢˜å¹²æ–‡æœ¬ï¼Œè¾“å‡ºæœ€ç›¸ä¼¼çš„ç« èŠ‚
def match_chapter(question_text: str, top_k: int = 5):
    q_vec = model.encode(question_text, normalize_embeddings=True)
    D, I = index.search(np.array([q_vec]), top_k)
    results = []
    for score, idx in zip(D[0], I[0]):
        results.append({
            "id": chapter_ids[idx],
            "name": chapter_names[idx],
            "score": float(score)
        })
    return results

# Step 6: ç¤ºä¾‹æµ‹è¯•
test_question = "ä¸‹é¢å“ªç§æ–¹æ³•å¯ä»¥ä¸ºç½‘é¡µæ·»åŠ åŠ¨æ€æ•ˆæœï¼Ÿ"
matched = match_chapter(test_question)

print("ğŸ” åŒ¹é…ç»“æœ:")
for item in matched:
    print(f"- {item['name']}ï¼ˆå¾—åˆ†: {item['score']:.4f}ï¼‰")
